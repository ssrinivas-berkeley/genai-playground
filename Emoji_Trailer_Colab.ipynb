{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ede84a",
   "metadata": {},
   "source": [
    "\n",
    "# üé¨ Emoji ‚Üí Movie Trailer (Colab, compat‚Äëfixed)\n",
    "\n",
    "Turn a title + 5‚Äì7 emojis into a 20‚Äì30s **movie trailer**: storyboard frames, AI voiceover, captions, SFX/BGM, and a poster ‚Äî all in this one notebook.\n",
    "\n",
    "**How to use**  \n",
    "1) Run **Setup** ‚Üí 2) Run **Build Pipeline** ‚Üí 3) Set params in **Run Demo** and execute.  \n",
    "Outputs are saved to `results/` and previewed inline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5d740",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf80af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install/upgrade deps. tqdm>=4.67 is required by some Colab packages.\n",
    "!pip -q install --upgrade moviepy==1.0.3 Pillow==10.4.0 numpy==2.0.2 gTTS tqdm>=4.67 imageio-ffmpeg\n",
    "\n",
    "import os, wave, contextlib\n",
    "from pathlib import Path\n",
    "\n",
    "# Folders\n",
    "RESULTS = Path(\"results\"); FRAMES = RESULTS / \"frames\"\n",
    "RESULTS.mkdir(exist_ok=True, parents=True); FRAMES.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"‚úÖ Dependencies installed. Folders ready at\", RESULTS.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed71316d",
   "metadata": {},
   "source": [
    "## üß∞ Pillow compatibility shim (textsize ‚Üí textbbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pillow 10+ removed ImageDraw.textsize. Provide a shim that maps to textbbox measurements.\n",
    "from PIL import ImageDraw as _ID\n",
    "\n",
    "def _compat_textsize(self, text, font=None, *args, **kwargs):\n",
    "    # Returns (w, h) using textbbox\n",
    "    bbox = self.textbbox((0,0), text, font=font, *args, **kwargs)\n",
    "    return (bbox[2]-bbox[0], bbox[3]-bbox[1])\n",
    "\n",
    "if not hasattr(_ID.ImageDraw, \"textsize\"):\n",
    "    _ID.ImageDraw.textsize = _compat_textsize  # type: ignore[attr-defined]\n",
    "\n",
    "print(\"‚úÖ Pillow textsize shim active\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a40f1",
   "metadata": {},
   "source": [
    "## üß± Build Pipeline (utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import wave, contextlib\n",
    "\n",
    "def split_sentences(text: str):\n",
    "    import re\n",
    "    parts = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [p for p in parts if p]\n",
    "\n",
    "def alloc_durations(total_s: float, sentences: List[str]) -> List[Tuple[str, float]]:\n",
    "    weights = [max(5, len(s)) for s in sentences]  # avoid zero\n",
    "    total_w = sum(weights) if sum(weights) else 1\n",
    "    return [(s, total_s * (w/total_w)) for s, w in zip(sentences, weights)]\n",
    "\n",
    "def seconds_to_srt(ts: float) -> str:\n",
    "    h = int(ts // 3600); ts -= h*3600\n",
    "    m = int(ts // 60);   ts -= m*60\n",
    "    s = int(ts);         ms = int((ts - s) * 1000)\n",
    "    return f\"{h:02}:{m:02}:{s:02},{ms:03}\"\n",
    "\n",
    "def save_wav_from_array(path: str, sr: int, data: np.ndarray):\n",
    "    data16 = np.int16(np.clip(data, -1.0, 1.0) * 32767)\n",
    "    with wave.open(path, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sr)\n",
    "        wf.writeframes(data16.tobytes())\n",
    "\n",
    "print(\"‚úÖ Utils loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce73da1",
   "metadata": {},
   "source": [
    "## üß† Script generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "STYLE_CARDS = {\n",
    "    \"noir\":  {\"palette\": [\"#0b0b0b\", \"#e5e5e5\"], \"tone\":\"gritty\", \"camera\":[\"close-up\",\"low-angle\",\"silhouette\"]},\n",
    "    \"anime\": {\"palette\": [\"#111122\", \"#ff4d6d\", \"#2ec4b6\"], \"tone\":\"epic\", \"camera\":[\"wide\",\"dynamic\",\"over-shoulder\"]},\n",
    "    \"vhs\":   {\"palette\": [\"#0f0f1a\", \"#b2f7ef\", \"#f7d6e0\"], \"tone\":\"retro\", \"camera\":[\"medium\",\"zoom\",\"handheld\"]},\n",
    "}\n",
    "\n",
    "EMOJI_HINTS = {\n",
    "    \"ü§ñ\":{\"topic\":\"AI\",\"mood\":\"tech\"}, \"üî•\":{\"topic\":\"action\",\"mood\":\"intense\"},\n",
    "    \"üé≠\":{\"topic\":\"drama\",\"mood\":\"serious\"}, \"üåÉ\":{\"topic\":\"city\",\"mood\":\"nocturnal\"},\n",
    "    \"üíé\":{\"topic\":\"heist\",\"mood\":\"slick\"}, \"üß†\":{\"topic\":\"mind\",\"mood\":\"clever\"},\n",
    "    \"üöÄ\":{\"topic\":\"space\",\"mood\":\"adventure\"}, \"üåä\":{\"topic\":\"ocean\",\"mood\":\"calm\"},\n",
    "    \"‚ö°Ô∏è\":{\"topic\":\"power\",\"mood\":\"charged\"}, \"üçú\":{\"topic\":\"food\",\"mood\":\"comfort\"},\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class Beat:\n",
    "    title: str\n",
    "    narration: str\n",
    "    line: str\n",
    "    mood: str\n",
    "\n",
    "@dataclass\n",
    "class TrailerPlan:\n",
    "    beats: List[Beat]\n",
    "    style: str\n",
    "    palette: list\n",
    "\n",
    "def _emoji_topics(emojis: List[str]) -> List[str]:\n",
    "    topics = []\n",
    "    for e in emojis:\n",
    "        if e in EMOJI_HINTS:\n",
    "            topics.append(EMOJI_HINTS[e][\"topic\"])\n",
    "    return topics or [\"mystery\"]\n",
    "\n",
    "def _dominant_mood(emojis: List[str]) -> str:\n",
    "    moods = [EMOJI_HINTS[e][\"mood\"] for e in emojis if e in EMOJI_HINTS]\n",
    "    return moods[0] if moods else \"epic\"\n",
    "\n",
    "def generate_trailer_plan(title: str, emojis: List[str], style: str=\"anime\") -> TrailerPlan:\n",
    "    topics = _emoji_topics(emojis)\n",
    "    mood = _dominant_mood(emojis)\n",
    "    style_card = STYLE_CARDS.get(style, STYLE_CARDS[\"anime\"])\n",
    "    tone = style_card[\"tone\"]\n",
    "\n",
    "    outline = [\n",
    "        (\"Hook\",          f\"In a world of {', '.join(topics[:2])}...\",            \"CHAR A: I wasn't ready for this.\"),\n",
    "        (\"World\",         f\"Neon streets hum, secrets simmer beneath.\",           \"CHAR B: You hear that? It's starting.\"),\n",
    "        (\"Conflict\",      f\"But when fate collides with {topics[-1]}...\",         \"CHAR A: We either run‚Äîor rewrite the rules.\"),\n",
    "        (\"Escalation\",    f\"Chases, whispers, and a countdown ticking to zero.\",  \"CHAR B: On my mark. Three... two...\"),\n",
    "        (\"Twist\",         f\"The truth is not what it seems‚Äîit's louder.\",         \"CHAR A: We were the signal all along.\"),\n",
    "        (\"Call-To-Action\",f\"This {tone} story hits now.\",                          \"NARRATOR: This is just the trailer.\"),\n",
    "    ]\n",
    "\n",
    "    beats = [Beat(bt, narr, line, mood) for bt, narr, line in outline]\n",
    "    return TrailerPlan(beats=beats, style=style, palette=style_card[\"palette\"])\n",
    "\n",
    "print(\"‚úÖ Script generator ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f0dbf",
   "metadata": {},
   "source": [
    "## üé¨ Prompt composition (shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d46162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "\n",
    "CAMERA = {\n",
    "    \"close-up\": {\"zoom\":1.1, \"pan\":0.0},\n",
    "    \"wide\":     {\"zoom\":1.0, \"pan\":0.05},\n",
    "    \"low-angle\":{\"zoom\":1.05,\"pan\":0.02},\n",
    "    \"dynamic\":  {\"zoom\":1.12,\"pan\":0.06},\n",
    "    \"over-shoulder\":{\"zoom\":1.03,\"pan\":0.03},\n",
    "    \"zoom\":     {\"zoom\":1.15,\"pan\":0.0},\n",
    "    \"handheld\": {\"zoom\":1.08,\"pan\":0.04},\n",
    "    \"medium\":   {\"zoom\":1.02,\"pan\":0.02},\n",
    "    \"silhouette\":{\"zoom\":1.0, \"pan\":0.03},\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class Shot:\n",
    "    text: str\n",
    "    camera: str\n",
    "    zoom: float\n",
    "    pan: float\n",
    "    color: str\n",
    "\n",
    "def compose_shots(plan, style_card_cameras: list[str]=None) -> list[Shot]:\n",
    "    cams = style_card_cameras or [\"wide\",\"close-up\",\"dynamic\",\"medium\",\"low-angle\",\"zoom\"]\n",
    "    shots = []\n",
    "    palette = plan.palette\n",
    "    for i, beat in enumerate(plan.beats):\n",
    "        cam = random.choice(cams)\n",
    "        z, p = CAMERA[cam][\"zoom\"], CAMERA[cam][\"pan\"]\n",
    "        color = palette[i % len(palette)]\n",
    "        text = f\"{beat.title}: {beat.narration}\"\n",
    "        shots.append(Shot(text=text, camera=cam, zoom=z, pan=p, color=color))\n",
    "    return shots\n",
    "\n",
    "print(\"‚úÖ Prompt composer ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf919de0",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Procedural image generation (Pillow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "\n",
    "def _vignette(img: Image.Image):\n",
    "    w, h = img.size\n",
    "    mask = Image.new('L', (w, h), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.ellipse((-int(.2*w), -int(.2*h), int(1.2*w), int(1.2*h)), fill=255)\n",
    "    mask = mask.filter(ImageFilter.GaussianBlur(radius=int(min(w,h)*0.08)))\n",
    "    black = Image.new('RGB', (w,h), (0,0,0))\n",
    "    return Image.composite(img, black, mask)\n",
    "\n",
    "def _draw_text(img, text, color, pos):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"DejaVuSans.ttf\", 32)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    draw.text(pos, text, fill=color, font=font)\n",
    "    return img\n",
    "\n",
    "def generate_images(shots, outdir: Path, size=(1280, 720)) -> list[Path]:\n",
    "    outpaths = []\n",
    "    for i, shot in enumerate(shots):\n",
    "        img = Image.new('RGB', size, shot.color)\n",
    "        # subtle gradient stripes\n",
    "        stripe_color = tuple(int(int(shot.color.strip(\"#\")[j:j+2],16)*0.8) for j in (0,2,4))\n",
    "        stripe = Image.new('RGB', (size[0], 10), stripe_color)\n",
    "        for y in range(0, size[1], 20):\n",
    "            img.paste(stripe, (0, y))\n",
    "        img = _vignette(img)\n",
    "\n",
    "        cue = f\"üé• {shot.camera}  üîçx{shot.zoom:.2f}  ‚Üî {shot.pan:.2f}\"\n",
    "        img = _draw_text(img, cue, (255,255,255), (40, size[1]-80))\n",
    "        img = _draw_text(img, (shot.text[:70] + (\"...\" if len(shot.text)>70 else \"\")), (235,235,235), (40, 40))\n",
    "\n",
    "        p = outdir / f\"frame_{i:02}.png\"\n",
    "        img.save(p)\n",
    "        outpaths.append(p)\n",
    "    return outpaths\n",
    "\n",
    "print(\"‚úÖ Image generator ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c02a4a",
   "metadata": {},
   "source": [
    "## üîä Text‚Äëto‚Äëspeech (gTTS) & timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gtts import gTTS\n",
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "def synthesize_voice_gtts(text: str, mp3_path: str=\"results/vo.mp3\"):\n",
    "    # gTTS requires internet. For offline, swap with pyttsx3 + espeak.\n",
    "    tts = gTTS(text)\n",
    "    tts.save(mp3_path)\n",
    "    dur = AudioFileClip(mp3_path).duration  # ffmpeg via imageio-ffmpeg\n",
    "    sentences = split_sentences(text)\n",
    "    alloc = alloc_durations(dur, sentences)\n",
    "    return mp3_path, alloc\n",
    "\n",
    "print(\"‚úÖ TTS ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95190a47",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Assembly (MoviePy) + captions + audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, CompositeAudioClip, CompositeVideoClip\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "def make_music(out=\"results/music.wav\", sr=22050, seconds=24.0, bpm=96):\n",
    "    t = np.linspace(0, seconds, int(sr*seconds), endpoint=False)\n",
    "    base = 0.05*np.sin(2*np.pi*220*t)  # pad\n",
    "    beat_int = 60.0 / bpm / 2  # half-beat\n",
    "    clicks = np.zeros_like(t)\n",
    "    for k in range(int(seconds/beat_int)):\n",
    "        start = int((k*beat_int)*sr)\n",
    "        clicks[start:start+200] += np.hanning(200)*0.6\n",
    "    audio = np.clip(base + clicks, -1, 1)\n",
    "    save_wav_from_array(out, sr, audio)\n",
    "    return out\n",
    "\n",
    "def make_sfx(out=\"results/sfx.wav\", sr=22050, seconds=24.0):\n",
    "    t = np.linspace(0, seconds, int(sr*seconds), endpoint=False)\n",
    "    whoosh = 0.08*np.sin(2*np.pi*55*t) * np.exp(-t*2.0)\n",
    "    save_wav_from_array(out, sr, whoosh)\n",
    "    return out\n",
    "\n",
    "def caption_image(size, text):\n",
    "    W, H = size\n",
    "    img = Image.new('RGBA', size, (0,0,0,0))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"DejaVuSans.ttf\", 48)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    # simple wrapped text\n",
    "    lines = []\n",
    "    words = text.split()\n",
    "    line = \"\"\n",
    "    for w in words:\n",
    "        test = (line + \" \" + w).strip()\n",
    "        if len(test) > 40:\n",
    "            lines.append(line); line = w\n",
    "        else:\n",
    "            line = test\n",
    "    if line: lines.append(line)\n",
    "    y = H - 150 - 50*len(lines)\n",
    "    for L in lines:\n",
    "        tw, th = draw.textsize(L, font=font)\n",
    "        draw.text(((W-tw)//2, y), L, font=font, fill=(255,255,255,230))\n",
    "        y += th + 6\n",
    "    return np.array(img)\n",
    "\n",
    "def assemble_video(frame_paths, narration_mp3, alloc, vertical=False, out_mp4=\"results/trailer.mp4\"):\n",
    "    # durations\n",
    "    dur_total = sum(d for _, d in alloc)\n",
    "    per_frame = dur_total / max(1, len(frame_paths))\n",
    "\n",
    "    # base video (Ken Burns via slight resize over time)\n",
    "    clips = []\n",
    "    for i, p in enumerate(frame_paths):\n",
    "        imgc = ImageClip(str(p)).set_duration(per_frame)\n",
    "        zoom = 1.02 + (i % 3)*0.01\n",
    "        clip = imgc.resize(lambda t: zoom ** (t/per_frame))\n",
    "        clips.append(clip)\n",
    "    v = concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "    # caption overlays\n",
    "    caption_clips = []\n",
    "    t_cursor = 0.0\n",
    "    for sent, dur in alloc:\n",
    "        cap = ImageClip(caption_image(v.size, sent), ismask=False).set_duration(dur).set_start(t_cursor)\n",
    "        caption_clips.append(cap.set_position((\"center\",\"center\")).set_opacity(1.0))\n",
    "        t_cursor += dur\n",
    "\n",
    "    V = CompositeVideoClip([v] + caption_clips)\n",
    "\n",
    "    # audio\n",
    "    nar = AudioFileClip(narration_mp3)\n",
    "    music = AudioFileClip(make_music(seconds=V.duration))\n",
    "    sfx = AudioFileClip(make_sfx(seconds=V.duration))\n",
    "    V = V.set_audio(CompositeAudioClip([music.volumex(0.35), sfx.volumex(0.5), nar.volumex(1.0)]))\n",
    "\n",
    "    if vertical:\n",
    "        V = V.resize(height=1920).crop(x_center=V.w/2, width=1080, height=1920)\n",
    "\n",
    "    V.write_videofile(out_mp4, fps=24, codec=\"libx264\", audio_codec=\"aac\", threads=4, preset=\"medium\")\n",
    "    return out_mp4\n",
    "\n",
    "def build_captions_srt(alloc, out=\"results/captions.srt\"):\n",
    "    lines = []\n",
    "    cur = 0.0\n",
    "    for i, (sent, dur) in enumerate(alloc, start=1):\n",
    "        start = seconds_to_srt(cur); end = seconds_to_srt(cur+dur)\n",
    "        lines += [str(i), f\"{start} --> {end}\", sent, \"\"]\n",
    "        cur += dur\n",
    "    Path(out).write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    return out\n",
    "\n",
    "print(\"‚úÖ Assembly ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a374bd",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Poster builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f846ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def make_poster(from_frame: Path, title: str, tagline: str, out=\"results/poster.png\"):\n",
    "    img = Image.open(from_frame).copy().convert(\"RGBA\")\n",
    "    w, h = img.size\n",
    "    overlay = Image.new('RGBA', (w,h), (0,0,0,0))\n",
    "    draw = ImageDraw.Draw(overlay)\n",
    "    try:\n",
    "        title_font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", 96)\n",
    "        tag_font = ImageFont.truetype(\"DejaVuSans.ttf\", 48)\n",
    "    except:\n",
    "        title_font = ImageFont.load_default()\n",
    "        tag_font = ImageFont.load_default()\n",
    "    tw, th = draw.textsize(title, font=title_font)\n",
    "    draw.text(((w-tw)//2, int(h*0.1)), title, font=title_font, fill=(255,255,255,230))\n",
    "    draw.text((int(w*0.1), int(h*0.8)), tagline, font=tag_font, fill=(240,240,240,230))\n",
    "    out_img = Image.alpha_composite(img, overlay)\n",
    "    out_img.save(out)\n",
    "    return out\n",
    "\n",
    "print(\"‚úÖ Poster maker ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd3416",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Run Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eff143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Video, Image as IPyImage, display\n",
    "\n",
    "# === Params ===\n",
    "TITLE = \"EMOJI HEIST\"\n",
    "EMOJIS = \"üß†üíéüï∂Ô∏èüöóüí•üé≠üåÉ\"\n",
    "STYLE = \"noir\"          # \"anime\" | \"noir\" | \"vhs\"\n",
    "VERTICAL = False        # True ‚Üí 9:16 crop for social\n",
    "\n",
    "# === Pipeline ===\n",
    "print(f\"üé¨ Title: {TITLE}\")\n",
    "print(f\"üòÄ Emojis: {EMOJIS}\")\n",
    "print(f\"üé® Style: {STYLE}   üì± Vertical: {VERTICAL}\")\n",
    "\n",
    "emojis = [e for e in EMOJIS if not e.isspace()]\n",
    "plan = generate_trailer_plan(TITLE, emojis, style=STYLE)\n",
    "narration = \" \".join([b.narration for b in plan.beats])\n",
    "\n",
    "shots = compose_shots(plan)\n",
    "frame_paths = generate_images(shots, Path('results/frames'))\n",
    "print(f\"üñºÔ∏è Generated {len(frame_paths)} frames ‚Üí results/frames\")\n",
    "\n",
    "vo_path, alloc = synthesize_voice_gtts(narration, mp3_path=\"results/vo.mp3\")\n",
    "srt_path = build_captions_srt(alloc)\n",
    "print(f\"üîä Voice: {vo_path} | ‚è± captions: {srt_path}\")\n",
    "\n",
    "mp4 = assemble_video(frame_paths, vo_path, alloc, vertical=VERTICAL, out_mp4=\"results/trailer.mp4\")\n",
    "print(f\"üéûÔ∏è Trailer: {mp4}\")\n",
    "\n",
    "poster = make_poster(frame_paths[0], TITLE, f\"A {STYLE.title()} Story\", out=\"results/poster.png\")\n",
    "print(f\"üñºÔ∏è Poster: {poster}\")\n",
    "\n",
    "display(Video(mp4, embed=True, html_attributes=\"controls preload\"))\n",
    "display(IPyImage(filename=poster))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}