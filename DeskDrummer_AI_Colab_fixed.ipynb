{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1473eac",
   "metadata": {},
   "source": [
    "\n",
    "# 🥁 DeskDrummer AI — Tap-to-Track (Colab, fixed)\n",
    "\n",
    "Turn desk taps into a mini song. Upload or record a short audio; the notebook detects onsets, estimates tempo, quantizes a beat, and generates drums+bass+hi-hats.\n",
    "\n",
    "**How to use**\n",
    "1. Run **Setup**.\n",
    "2. Upload or record an audio.\n",
    "3. Run **Make Song** to generate and play your track.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956dc737",
   "metadata": {},
   "source": [
    "## 🛠️ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -q install --upgrade librosa==0.10.2.post1 soundfile==0.12.1 numpy==2.0.2 scipy==1.13.1 pydub==0.25.1\n",
    "import numpy as np, librosa, soundfile as sf, os, io, base64, math\n",
    "from IPython.display import Audio, display, Javascript\n",
    "from scipy.signal import sawtooth\n",
    "from pathlib import Path\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "SR = 22050\n",
    "print(\"✅ Installed. SR =\", SR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf805f",
   "metadata": {},
   "source": [
    "## ☁️ Upload an audio (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5247789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files\n",
    "audio_path = None\n",
    "uploaded = files.upload()\n",
    "for k in uploaded:\n",
    "    audio_path = k\n",
    "    break\n",
    "if audio_path:\n",
    "    print(\"📁 Using uploaded file:\", audio_path)\n",
    "else:\n",
    "    print(\"ℹ️ No file uploaded — you can record in the next cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa9031",
   "metadata": {},
   "source": [
    "## 🎙️ Record from microphone (Chrome recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Uses MediaRecorder to capture ~4s of audio in-browser, then converts to WAV.\n",
    "from google.colab import output\n",
    "from IPython.display import Javascript\n",
    "record_js = r'''\n",
    "const sleep = time => new Promise(resolve => setTimeout(resolve, time));\n",
    "var recordAudio = () => new Promise(async resolve => {\n",
    "  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
    "  const mediaRecorder = new MediaRecorder(stream);\n",
    "  const audioChunks = [];\n",
    "  mediaRecorder.addEventListener(\"dataavailable\", event => { audioChunks.push(event.data); });\n",
    "  const start = () => mediaRecorder.start();\n",
    "  const stop = () => new Promise(resolve => {\n",
    "    mediaRecorder.addEventListener(\"stop\", async () => {\n",
    "      const audioBlob = new Blob(audioChunks);\n",
    "      const arrayBuffer = await audioBlob.arrayBuffer();\n",
    "      const base64String = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));\n",
    "      resolve(base64String);\n",
    "    });\n",
    "    mediaRecorder.stop();\n",
    "    stream.getTracks().forEach(t => t.stop());\n",
    "  });\n",
    "  resolve({ start, stop });\n",
    "});\n",
    "var record = async (s=4) => {\n",
    "  const recorder = await recordAudio();\n",
    "  recorder.start();\n",
    "  await sleep(s*1000);\n",
    "  const audio = await recorder.stop();\n",
    "  return audio;\n",
    "};\n",
    "''';\n",
    "display(Javascript(record_js))\n",
    "print(\"Click allow mic access, then run the next cell to record.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import output\n",
    "import base64, soundfile as sf, numpy as np, io\n",
    "from pydub import AudioSegment\n",
    "\n",
    "if not 'audio_path' in globals() or audio_path is None:\n",
    "    duration = 4\n",
    "    b64 = output.eval_js(f\"record({duration})\")\n",
    "    binary = base64.b64decode(b64)\n",
    "    audio_io = io.BytesIO(binary)\n",
    "    try:\n",
    "        seg = AudioSegment.from_file(audio_io)  # webm/ogg -> decode via ffmpeg\n",
    "        samples = np.array(seg.get_array_of_samples()).astype(np.float32)\n",
    "        if seg.channels == 2:\n",
    "            samples = samples.reshape((-1, 2)).mean(axis=1)\n",
    "        samples = samples / (2**(8*seg.sample_width-1))\n",
    "        sf.write(\"tap.wav\", samples, seg.frame_rate)\n",
    "        audio_path = \"tap.wav\"\n",
    "        print(\"🎙️ Recorded to tap.wav\")\n",
    "    except Exception as e:\n",
    "        print(\"Recording decode failed:\", e)\n",
    "else:\n",
    "    print(\"Using previously uploaded file:\", audio_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c711d5",
   "metadata": {},
   "source": [
    "## 🎼 Make Song from your taps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert audio_path is not None, \"No audio selected. Upload or record first.\"\n",
    "y, sr = librosa.load(audio_path, sr=SR, mono=True)\n",
    "y = librosa.util.normalize(y)\n",
    "\n",
    "# Onset detection and tempo\n",
    "onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr, units='time')\n",
    "onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, units='time')\n",
    "\n",
    "print(f\"Estimated tempo: {tempo:.1f} BPM\")\n",
    "print(f\"Detected {len(onset_frames)} taps\")\n",
    "\n",
    "# Quantize taps to grid\n",
    "bpm = max(60, min(180, float(tempo))) if tempo>0 else 100.0\n",
    "beat_sec = 60.0 / bpm\n",
    "length = max(8, int(np.ceil((onset_frames[-1] if len(onset_frames)>0 else 8)/beat_sec)+4))\n",
    "grid = np.zeros(length)\n",
    "for t in onset_frames:\n",
    "    idx = int(round(t/beat_sec))\n",
    "    if 0 <= idx < length: grid[idx] = 1\n",
    "\n",
    "# Synthesize drums\n",
    "dur = int((length+2) * beat_sec * sr)\n",
    "audio = np.zeros(dur, dtype=np.float32)\n",
    "\n",
    "def env(n, a=0.005, d=0.2, sr=SR):\n",
    "    t = np.linspace(0, n/sr, n, False)\n",
    "    e = np.exp(-t/d)\n",
    "    e[:max(1,int(a*sr))] *= np.linspace(0,1,max(1,int(a*sr)))\n",
    "    return e\n",
    "\n",
    "def add_kick(t0):\n",
    "    n = int(0.25*sr); t = np.linspace(0, n/sr, n, False)\n",
    "    sine = np.sin(2*np.pi*(100*np.exp(-t*10))*t)\n",
    "    audio[t0:t0+n] += 0.6*sine*env(n, a=0.002, d=0.15)\n",
    "\n",
    "def add_snare(t0):\n",
    "    n = int(0.15*sr); noise = np.random.randn(n)\n",
    "    audio[t0:t0+n] += 0.3*noise*env(n, a=0.001, d=0.12)\n",
    "\n",
    "def add_hat(t0):\n",
    "    n = int(0.05*sr); noise = np.random.randn(n)\n",
    "    audio[t0:t0+n] += 0.15*noise*env(n, a=0.001, d=0.05)\n",
    "\n",
    "for i in range(length):\n",
    "    t0 = int(i*beat_sec*sr)\n",
    "    if grid[i] > 0: add_kick(t0)\n",
    "    if i % 2 == 0: add_snare(t0)\n",
    "    add_hat(t0); add_hat(t0 + int(0.5*beat_sec*sr))\n",
    "\n",
    "# Simple bass\n",
    "root_freq = 55\n",
    "for i in range(length):\n",
    "    if grid[i] > 0 or i % 4 == 0:\n",
    "        n = int(beat_sec*sr); t0 = int(i*beat_sec*sr)\n",
    "        t = np.linspace(0, n/sr, n, False)\n",
    "        wave = 0.25*np.sin(2*np.pi*root_freq*t)\n",
    "        audio[t0:t0+n] += wave*env(n, a=0.005, d=0.25)\n",
    "\n",
    "# Normalize & export\n",
    "mx = np.max(np.abs(audio)) + 1e-6\n",
    "audio = (audio / mx * 0.9).astype(np.float32)\n",
    "sf.write(\"results/deskdrummer_mix.wav\", audio, sr)\n",
    "print(\"✅ Wrote results/deskdrummer_mix.wav\")\n",
    "\n",
    "display(Audio(\"results/deskdrummer_mix.wav\", rate=sr))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}